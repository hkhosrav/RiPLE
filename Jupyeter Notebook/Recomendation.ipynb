{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import csv\n",
    "import os\n",
    "\n",
    "#settings\n",
    "KGw=1\n",
    "beta=0.1\n",
    "\n",
    "inputfolder = 'input'\n",
    "recomfolder = 'recoms'\n",
    "recommender='BiasedMatrixFactorization'\n",
    "fullsetFile = 'fullset.csv'\n",
    "predictionFile = 'predictions.csv'\n",
    "\n",
    "QTFile =\"QT.csv\"\n",
    "SQFile = \"SQ.csv\"\n",
    "RFile = \"R.csv\"\n",
    "# install MyMediaLite and point the EXEFILE to the rating_prediction.exe file\n",
    "#EXEFILE = '/Users/hassankhosravi/Dropbox/UQ/Projects/RecSysTEL/code/Libaries/MyMediaLite-3.11/lib/mymedialite/rating_prediction.exe'\n",
    "EXEFILE = '/Users/uqhkhosr/Dropbox/UQ/Projects/RecSysTEL/code/Libaries/MyMediaLite-3.11/lib/mymedialite/rating_prediction.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Returns a Dict that maps content of pathName/fileName/colNum to an index \n",
    "def mapContentToIndex(pathName, fileName, colNum):\n",
    "    qfile = pathName + \"/\" + fileName\n",
    "    csv_file = csv.reader(open(qfile, \"rU\"), delimiter=\",\")\n",
    "    csv_file.next()\n",
    "    map = {}\n",
    "    current =0\n",
    "    for row in csv_file:\n",
    "        tag = row[colNum]\n",
    "        if map.has_key(tag)==False:\n",
    "            map[tag]=current\n",
    "            current = current+1\n",
    "    return map\n",
    "\n",
    "# Returns a matrix Question by Tags where QTMat[i][j] is 1/g if i is tagged with g topics, including j and 0 otherwise\n",
    "def createTMatrix(pathName, fileName, qDict, qSize, tDict, tSize):\n",
    "    QTMat = np.zeros((qSize, tSize))\n",
    "    qfile = pathName + \"/\" + fileName\n",
    "    csv_file = csv.reader(open(qfile, \"rU\"), delimiter=\",\")\n",
    "    # csv_file.next() add this line if file has header    \n",
    "    for row in csv_file:\n",
    "        qid = row[0]\n",
    "        tag = row[1] \n",
    "        if qDict.has_key(qid)==True and tDict.has_key(tag)==True:\n",
    "            QTMat[qDict[qid]][tDict[tag]] =1\n",
    "        \n",
    "    sumRows = QTMat.sum(axis=1)\n",
    "    for i in range (1, len(sumRows)):\n",
    "        if sumRows[i]>0:\n",
    "            QTMat[i] = QTMat[i]/sumRows[i]\n",
    "    return QTMat\n",
    "\n",
    "\n",
    "# Loads file at pathName/FileNAme/ColNum into a matrix using uDict and qDict\n",
    "def load(pathName, fileName, colNum, uDict, uSize, qDict, qSize, delimiter ):\n",
    "    matrix = np.zeros((uSize, qSize))\n",
    "    qfile = pathName + \"/\" + fileName\n",
    "    csv_file = csv.reader(open(qfile, \"rU\"), delimiter=delimiter)\n",
    "    csv_file.next() #add this line if file has header    \n",
    "    i =0;\n",
    "    for row in csv_file:\n",
    "        id1 = row[0]\n",
    "        id2  = row[1] \n",
    "        value = row[colNum]\n",
    "        if uDict.has_key(id1)==True and qDict.has_key(id2)==True:\n",
    "            matrix[uDict[id1]][qDict[id2]] = value\n",
    "    return matrix\n",
    "\n",
    "\n",
    "#returns 1 for non zero cells\n",
    "def createIndexMatrix(M):\n",
    "    I_M = M.copy()\n",
    "    I_M[I_M > 0] = 1\n",
    "    I_M[I_M < 0] = 1\n",
    "    I_M[I_M == 0] = 0\n",
    "    return I_M\n",
    "\n",
    "\n",
    "def loadDataset(inputfolder):\n",
    "    tDict = mapContentToIndex(inputfolder, QTFile,1)\n",
    "    tSize = len(tDict)\n",
    "    uDict = mapContentToIndex(inputfolder,SQFile,0)\n",
    "    uSize = len(uDict)\n",
    "    qDict = mapContentToIndex(inputfolder, SQFile,1)\n",
    "    qSize = len(qDict)\n",
    "    T =  createTMatrix(inputfolder, QTFile, qDict, qSize, tDict, tSize)\n",
    "    A  = load(inputfolder, SQFile, 2, uDict, uSize, qDict, qSize,',')\n",
    "    I_A = createIndexMatrix(A)\n",
    "    D  = load(inputfolder,SQFile, 3, uDict, uSize, qDict, qSize,',')\n",
    "    D = D/D.max() #normalize\n",
    "    I_D  = createIndexMatrix(D)\n",
    "    P  = load(inputfolder, SQFile, 4, uDict, uSize, qDict, qSize,',')\n",
    "    P = P/P.max()\n",
    "    I_P  = createIndexMatrix(P)\n",
    "    return A, I_A, D, I_D, P, I_P, T, uDict, uSize, qDict, qSize, tDict, tSize        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# takes in a Matrix and returns a vector with mean of non zero values per column\n",
    "def computeNonZeroMean(M): \n",
    "    temp = M.copy()\n",
    "    temp[np.where(temp == 0)] = np.nan\n",
    "    x = np.nanmean(temp,axis=0)\n",
    "    y = np.nanstd(temp, axis=0)\n",
    "    return np.nan_to_num(x), np.nan_to_num(y)\n",
    "\n",
    "\n",
    "#computing knowledge gap per question. negative values indicate competencies\n",
    "def computeKnowledgeGap(A, D, I_D):\n",
    "    B = np.zeros((len(A), len(A[0])))\n",
    "    D_mean, D_std = computeNonZeroMean(D)\n",
    "    for i in range(0, len(A)):\n",
    "        for j in range(0 , len(A[0])):\n",
    "            if I_D[i][j]>0:\n",
    "                #print (1- A[i])*(0.5 - A[i])/( D[i]) + A[i]* (0.5 - A[i])/(1 - D[i])  \n",
    "                firstPart = (1- A[i][j])*(0 - A[i][j])/(1 + D_mean[j]) # contributes when answered incorrectly\n",
    "                secondPart =(1+A[i][j])* (0 - A[i][j])/(2 - D_mean[j])  # contributes when answered correctly\n",
    "                B[i][j] =   firstPart + secondPart \n",
    "    \n",
    "    return B\n",
    "\n",
    "# writes matrix R into PathName/FileName\n",
    "def WriteMatrixToTable(PathName, FileName, R, uDict, qDict, headings):\n",
    "    if not os.path.exists(PathName):\n",
    "        os.makedirs(PathName)\n",
    "        \n",
    "    FilePath = PathName + \"/\" + FileName\n",
    "    fr = open(FilePath, 'w')\n",
    "    try:\n",
    "        writer = csv.writer(fr)\n",
    "        if headings:\n",
    "            writer.writerow(headings)\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] <> 0:\n",
    "                    writer.writerow([uDict.keys()[uDict.values().index(i)], qDict.keys()[qDict.values().index(j)], R[i][j]])\n",
    "                    # writer.writerow([i, j, R[i][j]])\n",
    "    finally:\n",
    "        fr.close() \n",
    "        \n",
    "def combineKnowledgeGapPreference(A, D, P, I_P, I_D, KGw):\n",
    "    KG = computeKnowledgeGap(A,D,I_D)\n",
    "    \n",
    "    R = (KGw * KG + (1-KGw)*P) * I_P * I_D\n",
    "    return R        \n",
    "\n",
    "#creating a full testset to use the RecSys for initial prediction\n",
    "def createFullTestset(uDict, uSize, qDict, qSize):\n",
    "    testset = []\n",
    "    for ukey in uDict:\n",
    "        for qkey in qDict:\n",
    "            testset.append([ukey, qkey, 0])\n",
    "    return testset\n",
    "\n",
    "# writes listname to PathName/Filename using headings\n",
    "def createFile(PathName, FileName, listname, headings):\n",
    "    if not os.path.exists(PathName):\n",
    "        os.makedirs(PathName)\n",
    "    \n",
    "    FilePath = PathName + \"/\" + FileName\n",
    "    fr = open(FilePath, 'w')\n",
    "    try:\n",
    "        writer = csv.writer(fr)\n",
    "        if headings:\n",
    "            writer.writerow(headings)\n",
    "        for item in listname:\n",
    "            #Write item to outcsv\n",
    "            output=','.join(str(x) for x in item)\n",
    "            writer.writerow(item)\n",
    "    finally:\n",
    "        fr.close()\n",
    "\n",
    "#\n",
    "def LoadingR(A, D, P, I_P, I_D, uDict, uSize, qDict, qSize, KGw):\n",
    "    R = np.round(combineKnowledgeGapPreference(A, D, P, I_P, I_D, KGw),2) #generate R\n",
    "    I_R = createIndexMatrix(R)\n",
    "    WriteMatrixToTable(recomfolder, RFile, R, uDict, qDict,[])\n",
    "    fullset = createFullTestset(uDict, uSize, qDict, qSize)\n",
    "    createFile(recomfolder, fullsetFile, fullset, [])\n",
    "    return  R, I_R\n",
    "\n",
    "A, I_A, D, I_D, P, I_P, T, uDict, uSize,  qDict, qSize, tDict, tSize = loadDataset(inputfolder)\n",
    "R, I_R = LoadingR(A, D, P, I_P, I_D, uDict, uSize, qDict, qSize, KGw) #generate R   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creates the learning profile\n",
    "def LearingProfile(R,T, I_R):\n",
    "    impact = np.dot(R,T)\n",
    "    weight = np.dot(I_R, T)+1 # to avoid division by zero\n",
    "    LP = impact/weight\n",
    "    return LP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Engine\n",
    "## Traditional recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "\n",
    "def checkCreate(inputfolder):\n",
    "    directory = os.getcwd() + '/' + inputfolder\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def  RecSys(inputfolder, recomfolder, recommender, trainset, testset, output):\n",
    "    checkCreate(recomfolder)\n",
    "    executable = EXEFILE\n",
    "    check_output(\n",
    "                ['mono', executable,\n",
    "                '--training-file', recomfolder + '/' + trainset,\n",
    "                '--test-file', recomfolder + '/'+ testset,\n",
    "                '--recommender', recommender,            \n",
    "                '--prediction-file' , recomfolder + '/' + output])\n",
    "\n",
    "RecSys(inputfolder, recomfolder, recommender,RFile, fullsetFile, predictionFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating and Enhancing Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ehhancing the predictions from RecSysTel using the learning profile\n",
    "def updateRecommendation(R, LP, T,beta):\n",
    "    H = np.dot(LP, T.T)\n",
    "    Rprime = R + H*beta\n",
    "    return Rprime    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateRecommendations(KGw, beta):\n",
    "    # Load Data set\n",
    "    A, I_A, D, I_D, P, I_P, T, uDict, uSize,  qDict, qSize, tDict, tSize = loadDataset(inputfolder)\n",
    "    R, I_R = LoadingR(A, D, P, I_P, I_D, uDict, uSize, qDict, qSize, KGw) #generate R   \n",
    "\n",
    "    # creates learning profile \n",
    "    LP = LearingProfile(R,T, I_R)\n",
    "\n",
    "    # Run Recommender System\n",
    "    RecSys(inputfolder, recomfolder, recommender,RFile, fullsetFile, predictionFile)\n",
    "\n",
    "    # Ehhancing the predictions from RecSysTel using the learning profile\n",
    "    Rprime = load(recomfolder, predictionFile,2, uDict, uSize, qDict, qSize, \"\t\")\n",
    "    O = updateRecommendation(Rprime, LP, T,beta)    \n",
    "    return O\n",
    "\n",
    "# generated recommendations\n",
    "O = generateRecommendations(KGw, beta)\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q2\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "def recommendation(user, O):\n",
    "    row = uDict[user]\n",
    "    values = O[row].tolist() # recommendations\n",
    "    maxQuestionIndex = values.index(max(values)) #index of recom with highest value\n",
    "    qid = qDict.keys()[qDict.values().index(maxQuestionIndex)] #question of the recommended topic\n",
    "    return qid  \n",
    "\n",
    "print recommendation('u0', O)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
